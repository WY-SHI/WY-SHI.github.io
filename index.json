[{"authors":["WYSHI"],"categories":null,"content":"Weiyang Shi completed his PhD study (2017-2022) at the Brainnetome Center \u0026amp; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, supervised by Prof. Tianzi Jiang. Previously, he received the B. Eng degree from the Honors College of Northwestern Polytechnical University in 2017, under the supervision of Prof. Wu Gao and Prof. Lei Xie.\n","date":1611360000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1611360000,"objectID":"fedc6816b1feba47c6fb9fa90dbc7bbc","permalink":"/author/weiyang-shi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/weiyang-shi/","section":"authors","summary":"Weiyang Shi completed his PhD study (2017-2022) at the Brainnetome Center \u0026amp; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, supervised by Prof. Tianzi Jiang. Previously, he received the B.","tags":null,"title":"Weiyang Shi","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Wen Li","Lingzhong Fan","Weiyang Shi","et al."],"categories":null,"content":"","date":1666051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666051200,"objectID":"8bf886d0dbd5860245acf4a1615ea8a9","permalink":"/publication/cc2022_wl/","publishdate":"2022-10-18T00:00:00Z","relpermalink":"/publication/cc2022_wl/","section":"publication","summary":"Age-specific brain mapping is particularly important, serving as a basic and indispensable tool to study the normal development of children. In this study, we took advantage of longitudinal data to create the brain atlas specifically for preadolescent children.","tags":["Anatomical Connectivity","Brainnetome Atlas","Development","Diffusion MRI","Preadolescent Child"],"title":"Brainnetome Atlas of Preadolescent Children based on Anatomical Connectivity Profiles","type":"publication"},{"authors":["Weiyang Shi","Lingzhong Fan","Haiyan Wang","et al."],"categories":null,"content":"","date":1661385600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661385600,"objectID":"53cd78bc41585c881906c7e268bb0c57","permalink":"/publication/cc2022_wyshi/","publishdate":"2022-08-25T00:00:00Z","relpermalink":"/publication/cc2022_wyshi/","section":"publication","summary":"Utilizing a large-scale multisite SCZ dataset, we identified and validated 2 neuroanatomical subtypes with individual-level abnormal patterns of the tensor-based morphometric measurement.","tags":["Schizophrenia","Subtype","Structural MRI","Neuroimaging–clinic Association Analysis","Neuroimaging–transcription Association Analysis"],"title":"Two Subtypes of Schizophrenia Identified by an Individual-level Atypical Pattern of Tensor-based Morphometric Measurement","type":"publication"},{"authors":["Jin Li","Dan Cao","Vasileios Dimakopoulos","Weiyang Shi","et al."],"categories":null,"content":"","date":1642550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642550400,"objectID":"03ac953f83af650e353f02c4f5eddae8","permalink":"/publication/jon2022_jl/","publishdate":"2022-01-19T00:00:00Z","relpermalink":"/publication/jon2022_jl/","section":"publication","summary":"The hippocampus is a locus of working memory (WM) with anterior and posterior subregions that differ in their transcriptional and external connectivity patterns. However, the involvement and functional connections between these subregions in WM processing are poorly understood.","tags":["Working Memory","Anterior and Posterior Subregions of Hippocampus","Functional Connections","Intracranial EEG"],"title":"Anterior–Posterior Hippocampal Dynamics Support Working Memory Processing","type":"publication"},{"authors":["Weiyang Shi","Lingzhong Fan","Tianzi Jiang"],"categories":null,"content":"","date":1623628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623628800,"objectID":"1bde921990a2cdc1e4aafe6d007604af","permalink":"/publication/neuroscibull2021_wyshi/","publishdate":"2021-06-14T00:00:00Z","relpermalink":"/publication/neuroscibull2021_wyshi/","section":"publication","summary":"Neuroimaging made it possible to quantify brain structure and function. However, there are few neuroimaging biomarkers for the early diagnosis, prognosis, and evaluation of therapy for brain diseases.","tags":["Neuroimaging","Biomarker","Machine Learning","Brainnetome Atlas"],"title":"Developing Neuroimaging Biomarker for Brain Diseases with a Machine Learning Framework and the Brainnetome Atlas","type":"publication"},{"authors":["Weiyang Shi"],"categories":["Tutorial"],"content":"Collection of Papers, Tools and Ideas focusing on neuroscience and machine learning which are worth spreading.\n1. Papers 1.1. Mental Disorders  [AD] Qiu S, Joshi P S, Miller M I, et al. Development and validation of an interpretable deep learning framework for Alzheimer’s disease classification[J]. Brain, 2020. [AD] Varol E, Sotiras A, Davatzikos C, et al. HYDRA: Revealing heterogeneity of imaging and genetic patterns through a multiple max-margin discriminative analysis framework[J]. Neuroimage, 2017, 145: 346-364. [Survey] Zhang L, Wang M, Liu M, et al. A Survey on Deep Learning for Neuroimaging-based Brain Disorder Analysis[J]. arXiv preprint arXiv:2005.04573, 2020.  1.2. Neuroscience  Yang G R, Joglekar M R, Song H F, et al. Task representations in neural networks trained to perform many cognitive tasks[J]. Nature neuroscience, 2019, 22(2): 297-306. Finn E S, Shen X, Scheinost D, et al. Functional connectome fingerprinting: identifying individuals using patterns of brain connectivity[J]. Nature neuroscience, 2015, 18(11): 1664-1671. Cai B, Zhang G, Zhang A, et al. Functional connectome fingerprinting: Identifying individuals and predicting cognitive functions via autoencoder[J]. Human Brain Mapping, 2021, 42(9): 2691-2705.  1.3. Graph Representation  Sankar A , Wu Y , Gou L , et al. Dynamic Graph Representation Learning via Self-Attention Networks[J]. 2018. Rossi E, Chamberlain B, Frasca F, et al. Temporal Graph Networks for Deep Learning on Dynamic Graphs[J]. arXiv preprint arXiv:2006.10637, 2020.  1.4. Interpretable Machine Learning  Wan A, Dunlap L, Ho D, et al. NBDT: Neural-Backed Decision Trees[J]. arXiv preprint arXiv:2004.00221, 2020. Lundberg S M, Nair B, Vavilala M S, et al. Explainable machine-learning predictions for the prevention of hypoxaemia during surgery[J]. Nature Biomedical Engineering, 2018, 2(10): 749.  1.5. Unsupervised Learning  Dong J, Cong Y, Sun G, et al. What can be transferred: Unsupervised domain adaptation for endoscopic lesions segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 4023-4032. He K, Fan H, Wu Y, et al. Momentum contrast for unsupervised visual representation learning[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 9729-9738. Hu H, Xie L, Hong R, et al. Creating Something from Nothing: Unsupervised Knowledge Distillation for Cross-Modal Hashing[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 3123-3132. Lin Y, Xie L, Wu Y, et al. Unsupervised person re-identification via softened similarity learning[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 3390-3399. Tang H, Chen K, Jia K. Unsupervised Domain Adaptation via Structurally Regularized Deep Clustering[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 8725-8735. Wang D, Zhang S. Unsupervised Person Re-identification via Multi-label Classification[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 10981-10990. Ye M, Shen J. Probabilistic structural latent representation for unsupervised embedding[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 5457-5466. Yu Y, Odobez J M. Unsupervised Representation Learning for Gaze Estimation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 7314-7324. Zhan X, Xie J, Liu Z, et al. Online Deep Clustering for Unsupervised Representation Learning[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 6688-6697.   2. Tools 2.1. Freesurfer FreeSurfer is a software package for the analysis and visualization of structural and functional neuroimaging data from cross-sectional or longitudinal studies. [ WiKi]\n2.2. FSL FSL is a comprehensive library of analysis tools for FMRI, MRI and DTI brain imaging data. [ WiKi]\n2.3. BRANT BRAinNetome fMRI Toolkit \u0026ndash; MATLAB scripts/GUIs for fMRI data pre-/post-processes [ Github] [ Document]\n2.4. Clinica Software platform for clinical neuroimaging studies [ Github]\n2.5 Nilearn Machine learning for Neuro-Imaging in Python [ Document]\n2.6 Dipy DIPY is the paragon 3D/4D+ imaging library in Python. Contains generic methods for spatial normalization, signal processing, machine learning, statistical analysis and visualization of medical images. Additionally, it contains specialized methods for computational anatomy including diffusion, perfusion and structural imaging. [ tutorials]\n ","date":1611360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611360000,"objectID":"2820bfc6b229f3373450cbfa8e179449","permalink":"/post/cpti/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/cpti/","section":"post","summary":"Collection of Papers, Tools and Ideas focusing on neuroscience and machine learning which are worth spreading.","tags":["Paper","Tool","Machine Learning","Neuroimaging"],"title":"Reading and Tool List","type":"post"},{"authors":["Weiyang Shi"],"categories":["Tutorial"],"content":"当前针对半监督语义分割领域，在不同数据集上，SOTA的方法主要包含CutMix, ClassMix以及s4GAN_MLMT(数据来源 paperWithCode)，backbone主要采用DeepLab系列(v3+或v2).\nConsistency Regularization: predictions for unlabelled data should be invariant to perturbations.\n最大化类内embedding的相似度(multi domain).\n  分割backbone:\n​ a. DeepLab系列 - V3: atrous convolutions + spatial pyramid pooling\n​ b. Encoder-decoder networks 系列 - skip connections\n  1 CutMix ( Github)  French G , Laine S , Aila T , et al. Semi-supervised semantic segmentation needs strong, varied perturbations[J]. 2019.\n#Network Regularization, #Augmentation Strategies, #Mean Teacher Framework\n 1.1 前言摘录 网络正则化(Network Regularization)的思想在于要求网络对不同形式扰动后图片(未标注)输出一致性的预测结果(更像是一种数据增广技术).\n平滑性假设:相近的图片应该具备相同的标注；聚类假设: 决策面应该位于数据分布密度相对较低的区域；\n  MixUp, Cutout以及CutMix\n  MixUp: The inputs and target labels of two randomly chosen examples are blended using a randomly chosen factor. 将两张图片进行组合，例如$C=\\alpha{A}+(1-\\alpha){B}$\n  Cutout: Augment an image by masking a rectangular region to zero. 将图片的部分区域赋值为0.\n  CutMix: combines aspects of MixUp and CutOut, cutting a rectangular region from image B and pasting it over image A.将图片$B$的部分区域粘贴至图片$A$，形成新的图片。\n    Semi-supervised classification(主要讨论基于一致性正则化的半监督分类方法)\n组合监督损失(例如交叉熵)和无监督一致性损失\n 不同扰动后预测结果的一致性，当前预测与历史预测的一致性 Mean teacher model 通过约束学生网络和教师网络预测之间的一致性    GAN-based adversarial learning: 最小化真实标签与预测标签分布的差异\n  语义分割中的一致性正则化/约束(Consistency regularization):\n分类中的一致性约束：$L_{cons}=d(f_{\\theta}(x),f_{\\theta}(\\hat{x}))$，其中$\\hat{x}$为对$x$施加扰动后的图像，$d(·)$为距离度量；\n  1.2 主要方法   模型框架\n经典的扰动方式，如裁剪、缩放、旋转和颜色变化等，对输出类造成混淆的几率很低，也被证明对提高自然图像的分类准确率十分有效，同时该方法在一些医学图像分割问题上也有正面的效果，但是它对自然图像的分割任务却无效。\n  Cutout有利于提升网络对各种特征的挖掘利用能力，从而克服图像不同语义成分的多样性组合。\n 生成二值化mask M：随机选择一个矩形范围赋值为0 (随机选择矩形的大小和长宽比) 将原始图像$A$输入教师网络$g_{\\phi}$来产生伪标签(pseudo-targets)； 利用伪标签和扰动后的图像$\\hat{x}$来训练学生网络$f_{\\theta}$ 计算一致性损失$L_{cons}=||M{\\odot}(f_{\\theta}(M{\\odot}x)-g_{\\phi}(x))||^2$    CutMix\n 原始图像$x_a$和$x_b$,Mask $M$ (面积为图像的一半，随机长宽比和位置) 将原始图像属于教师网络产生伪标签$g_{\\phi}(x_a)$,$g_{\\phi}(x_b)$ 定义$mix(·)$函数：$mix(a,b,M)=(1-M){\\odot}a+M{\\odot}b$ 计算一致性损失$L_{cons}=||mix(g_{\\phi}(x_a),g_{\\phi}(x_b),M)-f_{\\theta}(mix(x_a, x_b,M))||^2$      1.3 Training Setup  segmentation networks:  DeepLab v2 network based on ImageNet pre-trained ResNet-101; Dense U-net based on DensetNet-161; DeepLab v3+; PSPNet   Loss function:  组合监督损失和一致性损失：$L_{sup}+L_{cons}$ 为保证两项损失keep balance,$L_{cons}$在类别维度求和，在空间维度求平均     2 ClassMix ( Github)  Olsson, Viktor, et al. \u0026ldquo;ClassMix: Segmentation-Based Data Augmentation for Semi-Supervised Learning.\u0026rdquo; arXiv preprint arXiv:2007.07936 (2020).\n#Network Regularization, #Augmentation Strategies, #Pseudo-labelling, #Mean Teacher Framework\n 个人感觉方法侧重于实例分割，提出了一种新的数据增广技术ClassMix\n2.1 对比CutMix与ClassMix   CutMix: randomized rectangular regions are cut out from one image and pasted onto another. (mask-based mixing)\n  ClassMix (a generalization of CutMix): makes use of segmentations to generate the binary masks, instead of rectangles. (segmentation-based augmentation strategies)\n在生成mask时区分前景和背景\n  基于DeepLab-v2的ClassMix优于CutMix (但预训练数据不同)，排行榜上未提供ClassMix利用V3+的结果\n  2.2 方法   ClassMix: 如上图所示，输入两张未标注的图片$A$和$B$，输出一张合成图片$X_A$以及其伪标签$Y_A$，将一张图片的前景部分(随机选择分割后的一半数量的类别)粘贴到另一张图片上，伪代码如下图所示：\n  Mean-Teacher Framework(a trend in state-of-the-art semi-supervised learning)\n  损失函数： $$ L(\\theta)=E[l(f_{\\theta}(X_L),Y_L)+{\\lambda}l(f_{\\theta}(X_A),Y_A)] $$ 其中$X_L$为数据集中已标注的数据，$X_A$为利用未标注数据根据ClassMix合成的数据，$l(·)$为交叉熵损失\n   3 S4GAN_MLMT ( Github)  Mittal S , Tatarchenko M , Brox T . Semi-Supervised Semantic Segmentation with High- and Low-level Consistency[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2019, PP(99):1-1.\n#dual-branch method, #Mean Teacher Framework, #Network Fusion\n 3.1 整体框架   Dual-branch\n GAN-based branch (Semi-Supervised Semantic Segmentation GAN, s4GAN): 解决分割问题中的低级错误(错误的形状、不准确的边界和不连贯的分割，如上图c)，利用判别器判别真实的标签以及网络预测的标签(feature matching loss)；执行分割任务(像素级分类) Semi-supervised multi-label classification branch (Multi-Label Mean Teacher, MLMT): 通过判断图像中出现的所有类别来解决分割中可能出现的标签类别错误(如上图d)；执行图片级分类。 Network Fusion：融合空间信息和类信息(类似于通道注意力机制)，MLMT分支产生的图像级类别标签用于filter s4GAN的输出。    GAN中的discriminator输出可以被当作一个质量评估模块，用于选择最好的预测结果用于后续的self-training；\n  3.2 方法   s4GAN for Semantic Segmentation\n分割网络$S$产生分割结果，concatenate原始图像与分割结果送入判别器来对齐真实标注与生成的分割图的分布。\n  训练分割网络$S$: 损失函数包括三部分(交叉熵损失，feature matching损失，self-training损失)，\na. 交叉熵损失用于像素级别分类(分割)\nb. feature matching损失$L_{fm}$用于最小化真实标注与预测分割图的mean discrepancy, 其中$D_k(·)$代表判别器第$k$层的输出结果。 $$ L_{fm}=||E_{(x^l,y^l)~D^l}[D_k(y^{l}{\\oplus}x^{l})]-E_{x^{u}{~}D^u}[D_k(S(x^{u}){\\oplus}x^{u})]|| $$ c. self-training损失用于保持生成器和判别器之间的动态平衡: 为无标注的图片选择生成器(分割网络$S$)输出的最优的分割结果(可以骗过判别器的结果)作为标注来进行监督训练，利用判别器输出的评分做选择(设定阈值) $$ L_{st}= \\begin{cases} -\\sum_{h,w,c}y^*logS(x^u), \u0026amp;\\text{if }D(S(x^u)){\\ge}\\gamma\\\n0,\u0026amp; \\text{otherwise} \\end{cases} $$ 其中，$y^*$是由$S(x^u)$产生的pseudo pixel-wise labels\n最终，损失函数为： $$ L_S=L_{ce}+{\\lambda}_{fm}L_{fm}+{\\lambda}_{st}L_{st} $$\n  训练判别网络$D$: $$ L_{D}=E_{(x^l,y^l)~D^l}[\\text{log}D(y^{l}{\\oplus}x^{l})]+E_{x^{u}{~}D^u}[\\text{log}(1-D(S(x^{u}){\\oplus}x^{u}))] $$\n    Multi-label Semi-supervised Classification\n使用 Mean Teacher framework 来进行semi-supervised multilabel image classification.\nStudent network $G_{\\theta}$ 和Teacher network $H_{{\\theta}^{'}}$的输入分别为同一张图像的不同扰动后的图像，Teacher network的参数权重是Student network参数的exponential moving average. Student network的损失函数为： $$ L_{MT}=-\\sum_{c}z^{l}(c)\\text{log}(G_{\\theta}(x^l)(c))+\\lambda_{cons}||G_{\\theta}(x^{'(u,l)}-H_{{\\theta}^{'}}(x^{(u,l)})||^2 $$ 其中，$x$和$x^{'}$是同一张图片的不同扰动，$z^{l}$是真实标签的multi-hot vector.\n  Network Fusion\n两个branch是分开训练的，最终采用Network Fusion的方式进行融合以得到最后的统一结果,思想为根据预测所得图片上出现的类别概率缩放其对应的分割图上的概率：\n$$ S(x)_{c}= \\begin{cases} 0, \u0026amp;\\text{if }G(x)_c{\\le}\\tau\\\nS(x)_c,\u0026amp; \\text{otherwise} \\end{cases} $$\n$S(x)_{c}$是第$c$类的分割图,$G(x_c)$是MLMT-branch的soft output, $\\tau=0.2$.\n   Supplement. Mean Teacher Framework  Tarvainen A , Valpola H . Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. NIPS 2017.\n Semi-supervised通常可将数据分为带标签、不带标签两部分。Mean Teacher Framework通常是指对无标签数据进行不同形式的数据增广，分别送入teacher model和student model (teacher model和student model采用相同的模型架构)，约束teacher model和student model对同一样本不同增广形式具有一致性输出。\n在训练过程中，首先利用标注数据对student model进行监督学习，随后利用无标注数据来优化teacher model，具体流程如下：\n 利用student模型对图像进行预测得到$y_i$,然后利用teacher model预测得到$y_{i}^{’}$； 约束预测结果$y_i$和$y_i^{'}$的一致性($mseLoss$或者$KLLoss$)，并结合有标注的图像计算监督损失($crossEntropyLoss$)，将两部分的损失函数进行梯度反传用于更新student model的参数 teacher model模型的参数通过计算与student模型参数的滑动平均得到。  $$ \\theta_{t}^{'} = {\\alpha}{\\theta}_{t-1}^{'}+(1-{\\alpha}){\\theta}_t $$\n​\t其中${\\theta}_t$为student model的参数，${\\theta}_t^{'}$为teacher model的参数。最后teacher model将作为最终的预测模型。\n","date":1603756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604016000,"objectID":"b8874a830a69f2203b8735df7c7848e4","permalink":"/post/semi-supervised-segmentation/","publishdate":"2020-10-27T00:00:00Z","relpermalink":"/post/semi-supervised-segmentation/","section":"post","summary":"半监督分割方法串讲.","tags":["Semi-supervised","Segmentation","Deep Learning"],"title":"半监督分割","type":"post"},{"authors":["Weiyang Shi","Kaibin Xu","Ming Song","Lingzhong Fan","Tianzi Jiang"],"categories":null,"content":"","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"5a85fff8a1430c15429afebcd2cbf1e9","permalink":"/publication/miccai2020_wyshi/","publishdate":"2020-10-01T00:00:00Z","relpermalink":"/publication/miccai2020_wyshi/","section":"publication","summary":"we propose a novel end-to-end framework, named Dual Spaces Mapping Net (DSM-Net), to map the neuroimaging features and clinical symptoms to a shared decoupled latent space, so that constrain the latent space into a solution space associated with detailed symptoms of SCZ.","tags":["Deep Learning","Schizophrenia","Diagnosis"],"title":"Constrain Latent Space for Schizophrenia Classification via Dual Space Mapping Net","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"}]